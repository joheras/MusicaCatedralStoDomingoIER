{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image2xml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1L6IGiL7jF3Yx3XGgCaV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joheras/MusicaCatedralStoDomingoIER/blob/main/Notebooks/SacarM%C3%BAsica/image2xml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWrQDuQzgER"
      },
      "source": [
        "# input.jpg $\\rightarrow$ output.xml\n",
        "### Cuaderon para transformar las predicciones al formato musicxml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZf7Tf-z0n3"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYFaTUzGXZEM"
      },
      "source": [
        "%%capture\n",
        "pip install py_midicsv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-6II1zFXa1u"
      },
      "source": [
        "%%capture\n",
        "pip install MIDIUtil"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNdS6oDRXefJ"
      },
      "source": [
        "%%capture\n",
        "pip install pretty_midi"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fP4txKMRJC"
      },
      "source": [
        "%%capture\n",
        "!pip install icevision[all]==0.5.1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr6Qv3WguvsF"
      },
      "source": [
        "%%capture\n",
        "!pip install torchtext==0.8.1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnOG4Q21_NuI"
      },
      "source": [
        "%%capture\n",
        "!pip install fastai --upgrade"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb78TEACykyo"
      },
      "source": [
        "%%capture\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install tesseract-ocr-spa\n",
        "!pip install pytesseract\n",
        "!pip install tesseract"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE5LjIRr02sY"
      },
      "source": [
        "from icevision.all import *\n",
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "import pickle\n",
        "import midiutil\n",
        "import pretty_midi\n",
        "from pytesseract import Output\n",
        "import pytesseract\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import patches\n",
        "from matplotlib import colors\n",
        "import statistics\n",
        "import py_midicsv as pm\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import music21 as m21"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NojspdWi06UX"
      },
      "source": [
        "## Dataset y funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz8NqEGc08QP"
      },
      "source": [
        "%%capture\n",
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRGcU-KF1co5"
      },
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1[0] < bb1[2]\n",
        "    assert bb1[1] < bb1[3]\n",
        "    assert bb2[0] < bb2[2]\n",
        "    assert bb2[1] < bb2[3]\n",
        "    x_left = max(bb1[0], bb2[0])\n",
        "    y_top = max(bb1[1], bb2[1])\n",
        "    x_right = min(bb1[2], bb2[2])\n",
        "    y_bottom = min(bb1[3], bb2[3])\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
        "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itb-D2561Wz6"
      },
      "source": [
        "d={'background':0,'claved':1, 'claves':2, 'clavef':3, 'nota1':4, 'nota2':5, 'nota4':6, 'nota1:2':7, 'nota1:4':8, 'notae':9, 'sos':10, 'bem':11, 'bec':12, 'sil0':13, 'sil1':14, 'sil2':15, 'sil1:2':16, 'sil1:4':17, '2x4':18, '3x4':19, '4x4':20, '6x8':21, 'punt':22, 'liga':23,'3':24,'line':25,'P2':26, 'nota1:8':27, 'cal':28, '3x2':29,'mf':30,'P1':31,'check':32,'3x8':33,'2x2':34}\n",
        "d = {v: k for k, v in d.items()}\n",
        "\n",
        "def qsort(bboxs,labels,scores):\n",
        "  if bboxs == []:\n",
        "    return bboxs,labels,scores\n",
        "  bbox = bboxs[0]\n",
        "  label = labels[0]\n",
        "  score = scores[0]\n",
        "  n = len(labels[1:])\n",
        "  bboxsL,labelsL,scoresL = qsort([b for b in bboxs[1:] if b[0] < bbox[0]],[labels[1:][i] for i in range(0,n) if bboxs[1:][i][0] < bbox[0]],[scores[1:][i] for i in range(0,n) if bboxs[1:][i][0] < bbox[0]])\n",
        "  bboxsU,labelsU,scoresU = qsort([b for b in bboxs[1:] if b[0] >= bbox[0]],[labels[1:][i] for i in range(0,n) if bboxs[1:][i][0] >= bbox[0]],[scores[1:][i] for i in range(0,n) if bboxs[1:][i][0] >= bbox[0]])\n",
        "\n",
        "  return bboxsL + [bbox] + bboxsU, labelsL + [label] + labelsU, scoresL + [score] + scoresU\n",
        "\n",
        "def image2pred(path):\n",
        "  test = cv2.imread(path)\n",
        "  Y,X,_=test.shape\n",
        "  infer_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=923), tfms.A.Normalize()])\n",
        "  infer_ds = Dataset.from_images([test], infer_tfms)\n",
        "  infer_dl = faster_rcnn.infer_dl(infer_ds, batch_size=1)\n",
        "  samples, preds = faster_rcnn.predict_dl(model=model, infer_dl=infer_dl)\n",
        "  L = []\n",
        "  labels = list(preds[0]['labels'])\n",
        "  bboxs = preds[0]['bboxes']\n",
        "  for i in range(0,len(labels)):\n",
        "    xmin=bboxs[i].xmin\n",
        "    ymin=bboxs[i].ymin-(samples[0]['img'].shape[0]-samples[0]['height'])/2\n",
        "    xmax=bboxs[i].xmax\n",
        "    ymax=bboxs[i].ymax-(samples[0]['img'].shape[0]-samples[0]['height'])/2\n",
        "    xmin=int(X*xmin/samples[0]['width'])\n",
        "    ymin=int(Y*ymin/samples[0]['height'])\n",
        "    xmax=int(X*xmax/samples[0]['width'])\n",
        "    ymax=int(Y*ymax/samples[0]['height'])\n",
        "    L.append([xmin,ymin,xmax,ymax])\n",
        "  scores = list(preds[0]['scores'])\n",
        "  L,labels,scores = qsort(L,labels,scores)\n",
        "  labels = [d[l] for l in labels]\n",
        "  \n",
        "  return L,labels,scores"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ5e5giC1hxB"
      },
      "source": [
        "def remove_notas(bboxs,labels,scores):\n",
        "  n = len(bboxs)\n",
        "  L = []\n",
        "  for i in range(0,n):\n",
        "    k = len(bboxs[i:])\n",
        "    bb1 = bboxs[i]\n",
        "    l1 = labels[i]\n",
        "    s1 = scores[i]\n",
        "    for j in range(0,k):\n",
        "      bb2 = bboxs[i:][j]\n",
        "      l2 = labels[i:][j]\n",
        "      s2 = scores[i:][j]\n",
        "      if bb1[2]-bb1[0] >= 55 and 'nota' in l1:\n",
        "        L.append(i)\n",
        "      elif get_iou(bb1, bb2) > 0.5 and 'nota' in l1 and 'nota' in l2:\n",
        "        if l1 > l2:\n",
        "          L.append(i+j)\n",
        "        if l1 < l2:\n",
        "          L.append(i)\n",
        "        if l1 == l2 and get_iou(bb1, bb2) < 1:\n",
        "          if s1 > s2:\n",
        "            L.append(i+j)\n",
        "          else:\n",
        "            L.append(i)\n",
        "  L = list(np.unique(L))\n",
        "  b,l,s = [],[],[]\n",
        "  for i in range(0,n):\n",
        "    if not(i in L):\n",
        "      b.append(bboxs[i])\n",
        "      l.append(labels[i])\n",
        "      s.append(scores[i])\n",
        "  return b,l,s"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9FHDDkh1jrn"
      },
      "source": [
        "## Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xk33ljW1vna"
      },
      "source": [
        "- **Detección**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-erFOLAa1k7P"
      },
      "source": [
        "%%capture\n",
        "state_dict = torch.load('mejor.pth')\n",
        "detector = faster_rcnn.model(num_classes=35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOfbCrd177o"
      },
      "source": [
        "detector.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQIuxPqv15vS"
      },
      "source": [
        "- **Clasificación altura notas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1a2_80U17pQ"
      },
      "source": [
        "%%capture\n",
        "altura_notas = load_learner('export.pkl')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSMEAyvk3uPE"
      },
      "source": [
        "## Predicción\n",
        "- Transforma la imagen en una secuencia de elementos musicales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHWeNv5yx8"
      },
      "source": [
        "  claves = {'claves':{-4:53, -3:55, -2:57, -1:59, 0:60, 1:62, 2:64, 3:65, 4:67, 5:69, 6:71, 7:72, 8:74, 9:76, 10:77, 11:79, 12:81, 13:83, 14:84},\n",
        "            'clavef':{-4:33, -3:35, -2:36, -1:38, 0:40, 1:41, 2:43, 3:45, 4:47, 5:48, 6:50, 7:52, 8:53, 9:55, 10:57, 11:59, 12:60, 13:62, 14:64},\n",
        "#Cambiar clave de do            'claved':{-4:33, -3:35, -2:36, -1:38, 0:40, 1:41, 2:43, 3:45, 4:47, 5:48, 6:50, 7:52, 8:53, 9:55, 10:57, 11:59, 12:60, 13:62, 14:64}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCExJfm74AwS"
      },
      "source": [
        "def predict(image): # opencv2 array o path\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}